{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules and functions\n",
    "import os, datetime\n",
    "import pandas as pd\n",
    "from ETL.ETL_general import update_incremental, update_incremental_api, get_most_recent_date, export_to_gsheets\n",
    "from ETL.ETL_garmin_api import init_garmin, get_garmin_data\n",
    "from ETL.ETL_whoop import init_whoop, get_sleep_recovery_data, get_journal_data\n",
    "from ETL.ETL_mfp_api import init_mfp, get_meal_data, get_meal_daily\n",
    "from ETL.ETL_mfp_apple_matching import update_meal_schedule\n",
    "from ETL.ETL_apple_health import get_food_time_data, get_weight_data\n",
    "from ETL.ETL_libreview import get_glucose_daily\n",
    "from ETL.ETL_trainingpeaks import get_tp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Cleaned/Food.csv: Data from 'Data/Apple health/exportacion.xml' from 2024-05-19 obtained\n",
      "Data/Cleaned/Food.csv: Data from 2024-05-19 (re-)written\n",
      "Data/Cleaned/Weight.csv: Data from 'Data/Apple health/exportacion.xml' from 2024-05-15 obtained\n",
      "Data/Cleaned/Weight.csv: Data from 2024-05-15 (re-)written\n",
      "Data/Cleaned/MFP meals scrapped.csv: Data per meal obtained and (re-)written for 2024-05-19\n",
      "Data/Cleaned/MFP per day scrapped.csv: Data per day obtained and (re-)written for 2024-05-19\n",
      "Meal schedule matching: Status on 2024-05-18: Infeasible\n",
      "Meal schedule matching: Status on 2024-05-19: Infeasible\n",
      "Data/Cleaned/MealSchedule.csv: Incremental meal scheduling results updated and (re-)written from 2024-05-18\n",
      "Data/Cleaned/Garmin_daily.csv: Data from API from 2024-05-19 obtained\n",
      "Data/Cleaned/Garmin_daily.csv: Data from 2024-05-19 (re-)written\n",
      "Data/Cleaned/Glucose_daily.csv: Data from 'Data/LibreLink/AlbertoRequena Izard_glucose.csv' from 2024-05-15 obtained\n",
      "Data/Cleaned/Glucose_daily.csv: Data from 2024-05-15 (re-)written\n",
      "Data/Cleaned/Sleep_and_recovery.csv: Data from API from 2024-05-19 obtained\n",
      "Data/Cleaned/Sleep_and_recovery.csv: Data from 2024-05-19 (re-)written\n",
      "Data/Cleaned/Journal.csv: Journal data obtained and rewritten'\n",
      "Data/Cleaned/TSS metrics.csv: Data rewritten as a whole, updated from 2024-05-19\n",
      "Clean data files updated\n"
     ]
    }
   ],
   "source": [
    "### Update data of intemediate clean files ###\n",
    "\n",
    "# Apple health update (food times and weight)\n",
    "apple_health_file_raw = 'Data/Apple health/exportacion.xml'\n",
    "food_times_file = 'Data/Cleaned/Food.csv'\n",
    "weight_file = 'Data/Cleaned/Weight.csv'\n",
    "update_incremental(apple_health_file_raw, food_times_file, get_food_time_data)\n",
    "update_incremental(apple_health_file_raw, weight_file, get_weight_data)\n",
    "\n",
    "# MyFitnessPal API update\n",
    "meals_file = 'Data/Cleaned/MFP meals scrapped.csv'\n",
    "meals_daily_file = 'Data/Cleaned/MFP per day scrapped.csv'\n",
    "meals_scheduled_file = 'Data/Cleaned/MealSchedule.csv'\n",
    "mfp_client = init_mfp()\n",
    "get_meal_data(mfp_client, meals_file)\n",
    "get_meal_daily(mfp_client, meals_daily_file)\n",
    "# Different format than the rest, directly writes\n",
    "\n",
    "# Food schedules matching\n",
    "update_meal_schedule(food_times_file, meals_file, meals_scheduled_file)\n",
    "### Need to understand why unfeasible ###\n",
    "\n",
    "# Garmin update\n",
    "garmin_file = 'Data/Cleaned/Garmin_daily.csv'\n",
    "email_g = os.getenv(\"USERNAME_G\")\n",
    "password_g = os.getenv(\"PASSWORD_G\")\n",
    "garmin_client = init_garmin(email_g, password_g)\n",
    "update_incremental_api(garmin_client, garmin_file, get_garmin_data)\n",
    "\n",
    "# Glucose update\n",
    "libreview_file_raw = 'Data/LibreLink/AlbertoRequena Izard_glucose.csv'\n",
    "glucose_daily_file = 'Data/Cleaned/Glucose_daily.csv'\n",
    "glucose_time_file = 'Data/Cleaned/Glucose.csv'\n",
    "update_incremental(libreview_file_raw, glucose_daily_file, get_glucose_daily)\n",
    "\n",
    "# Whoop API update\n",
    "whoop_file = 'Data/Cleaned/Sleep_and_recovery.csv'\n",
    "journal_file_raw = 'Data/Whoop/journal_entries.csv'\n",
    "journal_file = 'Data/Cleaned/Journal.csv'\n",
    "email_w = os.getenv(\"USERNAME_W\")\n",
    "password_w = os.getenv(\"PASSWORD_W\")\n",
    "whoop_client = init_whoop(email_w, password_w)\n",
    "update_incremental_api(whoop_client, whoop_file, get_sleep_recovery_data)\n",
    "get_journal_data(journal_file_raw, journal_file) # Not incremental for now\n",
    "\n",
    "# Trainingpeaks update\n",
    "tp_file_raw = 'Data/TrainingPeaks/workouts.csv'\n",
    "tp_file = 'Data/Cleaned/TSS metrics.csv'\n",
    "last_date = get_most_recent_date(tp_file)\n",
    "tp_data = get_tp_data(tp_file_raw)\n",
    "tp_data.to_csv('Data/Cleaned/TSS metrics.csv', index=False)\n",
    "print(f\"{tp_file}: Data rewritten as a whole, updated from {last_date}\")\n",
    "\n",
    "print(f'Clean data files updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSS metrics:  2023-05-20  to  2024-05-19\n",
      "Sleep and recovery:  2024-03-16  to  2024-05-19\n",
      "MFP per day scrapped:  2024-03-16  to  2024-05-19\n",
      "Glucose daily:  2024-03-23  to  2024-05-15\n",
      "Garmin daily:  2024-03-16  to  2024-05-19\n",
      "Journal:  2024-03-14  to  2024-05-18\n",
      "Weight:  2024-03-11  to  2024-05-15\n",
      "Integrated data file created:  2024-03-16  to  2024-05-18\n",
      "Uploaded to Google Sheets, sheet name:  Integrated_data\n"
     ]
    }
   ],
   "source": [
    "### Integrate into a single file ###\n",
    "\n",
    "### Get all key dfs from Cleaned Data\n",
    "import pandas as pd\n",
    "\n",
    "df_t = pd.read_csv('Data/Cleaned/TSS metrics.csv')\n",
    "df_s = pd.read_csv('Data/Cleaned/Sleep_and_recovery.csv')\n",
    "df_f = pd.read_csv('Data/Cleaned/MFP per day scrapped.csv')\n",
    "df_g = pd.read_csv('Data/Cleaned/Glucose_daily.csv')\n",
    "df_gar = pd.read_csv('Data/Cleaned/Garmin_daily.csv')\n",
    "df_j = pd.read_csv('Data/Cleaned/Journal.csv')\n",
    "df_w = pd.read_csv('Data/Cleaned/Weight.csv')\n",
    "\n",
    "# Print the min and the max date of each df\n",
    "print('TSS metrics: ', df_t['date'].min(),' to ',df_t['date'].max())\n",
    "print('Sleep and recovery: ',df_s['date'].min(),' to ',df_s['date'].max())\n",
    "print('MFP per day scrapped: ',df_f['date'].min(),' to ',df_f['date'].max())\n",
    "print('Glucose daily: ',df_g['date'].min(),' to ',df_g['date'].max())\n",
    "print('Garmin daily: ',df_gar['date'].min(),' to ',df_gar['date'].max())\n",
    "print('Journal: ',df_j['date'].min(),' to ',df_j['date'].max())\n",
    "print('Weight: ',df_w['date'].min(),' to ',df_w['date'].max())\n",
    "\n",
    "# Filter all dfs to the same date range, the one between the min and max date of all dfs except glucose and weight\n",
    "min_date = max(df_t['date'].min(),df_s['date'].min(),df_f['date'].min(), df_gar['date'].min(), df_j['date'].min())\n",
    "max_date = min(df_t['date'].max(),df_s['date'].max(),df_f['date'].max(), df_gar['date'].max(), df_j['date'].max())\n",
    "\n",
    "df_t = df_t[(df_t['date'] >= min_date) & (df_t['date'] <= max_date)]\n",
    "df_s = df_s[(df_s['date'] >= min_date) & (df_s['date'] <= max_date)]\n",
    "df_f = df_f[(df_f['date'] >= min_date) & (df_f['date'] <= max_date)]\n",
    "df_g = df_g[(df_g['date'] >= min_date) & (df_g['date'] <= max_date)]\n",
    "df_gar = df_gar[(df_gar['date'] >= min_date) & (df_gar['date'] <= max_date)]\n",
    "df_j = df_j[(df_j['date'] >= min_date) & (df_j['date'] <= max_date)]\n",
    "df_w = df_w[(df_w['date'] >= min_date) & (df_w['date'] <= max_date)]\n",
    "\n",
    "# Perform an outter join on all dfs\n",
    "df = df_t.merge(df_s, on='date', how='outer')\n",
    "df = df.merge(df_f, on='date', how='outer')\n",
    "df = df.merge(df_g, on='date', how='outer')\n",
    "df = df.merge(df_gar, on='date', how='outer')\n",
    "df = df.merge(df_j, on='date', how='outer')\n",
    "df = df.merge(df_w, on='date', how='outer')\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('Data/Cleaned/Integrated_data.csv', index=False)\n",
    "print('Integrated data file created: ',df['date'].min(),' to ',df['date'].max())\n",
    "\n",
    "# Export DataFrame to Google Sheets with specified sheet name\n",
    "sheet_name = 'Integrated_data'\n",
    "export_to_gsheets(df, sheet_name)\n",
    "print('Uploaded to Google Sheets, sheet name: ',sheet_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
