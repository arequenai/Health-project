{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSS metrics:  2023-05-17  to  2024-05-12\n",
      "Sleep and recovery:  2024-03-16  to  2024-05-15\n",
      "MFP per day scrapped:  2024-03-16  to  2024-05-15\n",
      "Glucose daily:  2024-03-23  to  2024-05-15\n",
      "Garmin daily:  2024-03-16  to  2024-05-15\n",
      "Journal:  2024-03-14  to  2024-05-14\n",
      "Weight:  2024-03-11  to  2024-05-15\n"
     ]
    }
   ],
   "source": [
    "### Get all key dfs from Cleaned Data\n",
    "import pandas as pd\n",
    "\n",
    "df_t = pd.read_csv('Data/Cleaned/TSS metrics.csv')\n",
    "df_s = pd.read_csv('Data/Cleaned/Sleep_and_recovery.csv')\n",
    "df_f = pd.read_csv('Data/Cleaned/MFP per day scrapped.csv')\n",
    "df_g = pd.read_csv('Data/Cleaned/Glucose_daily.csv')\n",
    "df_gar = pd.read_csv('Data/Cleaned/Garmin_daily.csv')\n",
    "df_j = pd.read_csv('Data/Cleaned/Journal.csv')\n",
    "df_w = pd.read_csv('Data/Cleaned/Weight.csv')\n",
    "\n",
    "# Print the min and the max date of each df\n",
    "print('TSS metrics: ', df_t['date'].min(),' to ',df_t['date'].max())\n",
    "print('Sleep and recovery: ',df_s['date'].min(),' to ',df_s['date'].max())\n",
    "print('MFP per day scrapped: ',df_f['date'].min(),' to ',df_f['date'].max())\n",
    "print('Glucose daily: ',df_g['date'].min(),' to ',df_g['date'].max())\n",
    "print('Garmin daily: ',df_gar['date'].min(),' to ',df_gar['date'].max())\n",
    "print('Journal: ',df_j['date'].min(),' to ',df_j['date'].max())\n",
    "print('Weight: ',df_w['date'].min(),' to ',df_w['date'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df:  2024-03-16  to  2024-05-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'TSS', 'CTL', 'ATL', 'TSB', 'sleep_time',\n",
       "       'sleep_score_performance', 'sleep_score_consistency',\n",
       "       'sleep_score_efficiency', 'sleep_duration', 'sleep_rem', 'sleep_deep',\n",
       "       'sleep_light', 'sleep_awake', 'recovery_score', 'resting_hr', 'hrv',\n",
       "       'spo2', 'skin_temp', 'calories_burned', 'carbs', 'fat', 'protein',\n",
       "       'sodium', 'sugar', 'calories_consumed', 'calories_goal', 'calories_net',\n",
       "       'calories_consumed_breakfast', 'calories_consumed_lunch',\n",
       "       'calories_consumed_dinner', 'calories_consumed_snacks', 'mean_glucose',\n",
       "       'std_glucose', 'max_glucose', 'wake_up_glucose', 'averageStressLevel',\n",
       "       'restStressPercentage', 'lowStressPercentage', 'mediumStressPercentage',\n",
       "       'highStressPercentage', 'stressQualifier', 'bodyBatteryHighestValue',\n",
       "       'bodyBatteryLowestValue', 'bodyBatteryDuringSleep',\n",
       "       'avoid_processed_foods', 'bed_full', 'sick_or_ill', 'injury', 'alcohol',\n",
       "       'read_bed', 'stretch', 'screen_bed', 'BMI', 'fat_percentage',\n",
       "       'lean_body_mass', 'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter all dfs to the same date range, the one between the min and max date of all dfs except glucose and weight\n",
    "min_date = max(df_t['date'].min(),df_s['date'].min(),df_f['date'].min(), df_gar['date'].min(), df_j['date'].min())\n",
    "max_date = min(df_t['date'].max(),df_s['date'].max(),df_f['date'].max(), df_gar['date'].max(), df_j['date'].max())\n",
    "\n",
    "df_t = df_t[(df_t['date'] >= min_date) & (df_t['date'] <= max_date)]\n",
    "df_s = df_s[(df_s['date'] >= min_date) & (df_s['date'] <= max_date)]\n",
    "df_f = df_f[(df_f['date'] >= min_date) & (df_f['date'] <= max_date)]\n",
    "df_g = df_g[(df_g['date'] >= min_date) & (df_g['date'] <= max_date)]\n",
    "df_gar = df_gar[(df_gar['date'] >= min_date) & (df_gar['date'] <= max_date)]\n",
    "df_j = df_j[(df_j['date'] >= min_date) & (df_j['date'] <= max_date)]\n",
    "df_w = df_w[(df_w['date'] >= min_date) & (df_w['date'] <= max_date)]\n",
    "\n",
    "# Perform an outter join on all dfs\n",
    "df = df_t.merge(df_s, on='date', how='outer')\n",
    "df = df.merge(df_f, on='date', how='outer')\n",
    "df = df.merge(df_g, on='date', how='outer')\n",
    "df = df.merge(df_gar, on='date', how='outer')\n",
    "df = df.merge(df_j, on='date', how='outer')\n",
    "df = df.merge(df_w, on='date', how='outer')\n",
    "\n",
    "# Check first and last date of the new df\n",
    "print('New df: ',df['date'].min(),' to ',df['date'].max())\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated data file created\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('Data/Cleaned/Integrated_data.csv', index=False)\n",
    "\n",
    "print('Integrated data file created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntegrated_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Export DataFrame to Google Sheets with specified sheet name\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m Export_Data_To_Sheets(\u001b[43mdf\u001b[49m, sheet_name)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUploaded to Google Sheets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "### Upload to Google Sheets\n",
    "\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Load service account credentials\n",
    "creds = service_account.Credentials.from_service_account_file('gsheets key.json')\n",
    "scoped_credentials = creds.with_scopes(['https://www.googleapis.com/auth/spreadsheets'])\n",
    "\n",
    "# Authenticate with Google Sheets API\n",
    "service = build('sheets', 'v4', credentials=scoped_credentials)\n",
    "\n",
    "# Spreadsheet ID and range for Health Dashboards\n",
    "SPREADSHEET_ID_input = '197VfZCekvBev0m1vsi8kUHpuO0IoTRA90_bQRGBYYSM'\n",
    "\n",
    "def Export_Data_To_Sheets(df, sheet_name):\n",
    "    # Specify the range including the sheet name\n",
    "    range_name = f\"{sheet_name}!A1:ZA1000\"\n",
    "    \n",
    "    # Fill NaN values with empty strings\n",
    "    df_filled = df.fillna('')\n",
    "    \n",
    "    # Get DataFrame headers and values\n",
    "    headers = [df_filled.columns.tolist()]\n",
    "    values = df_filled.values.tolist()\n",
    "    \n",
    "    # Concatenate headers with values\n",
    "    data = headers + values\n",
    "    \n",
    "    # Update the spreadsheet with DataFrame values including headers\n",
    "    response = service.spreadsheets().values().update(\n",
    "        spreadsheetId=SPREADSHEET_ID_input,\n",
    "        valueInputOption='RAW',\n",
    "        range=range_name,\n",
    "        body=dict(\n",
    "            majorDimension='ROWS',\n",
    "            values=data)\n",
    "    ).execute()\n",
    "\n",
    "# Specify the sheet name\n",
    "sheet_name = 'Integrated_data'\n",
    "\n",
    "# Export DataFrame to Google Sheets with specified sheet name\n",
    "Export_Data_To_Sheets(df, sheet_name)\n",
    "print('Uploaded to Google Sheets')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
